{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64c1697",
   "metadata": {},
   "source": [
    "<h3><center>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b53c3a",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [General information](#section_1_1)\n",
    "* [Online presence](#section_2_1)\n",
    "* [Review](#section_3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509a2de",
   "metadata": {},
   "source": [
    "### General information: <a class=\"anchor\" id=\"section_1_1\"></a>\n",
    "<b>Article name:</b> MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications </br>\n",
    "<b>Authors:</b> Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam </br>\n",
    "<b>Published on:</b> Mon, 17 Apr 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0a0bc",
   "metadata": {},
   "source": [
    "### Online presence: <a class=\"anchor\" id=\"section_2_1\"></a>\n",
    "https://arxiv.org/abs/1704.04861"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b26e3",
   "metadata": {},
   "source": [
    "### Review: <a class=\"anchor\" id=\"section_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0522d1d",
   "metadata": {},
   "source": [
    "<b>Abstract:</b> </br>\n",
    "Mobile devices have become integral components of modern society, necessitating the development of efficient convolutional neural network (CNN) architectures tailored for deployment on resource-constrained platforms. In response to this imperative, MobileNets have emerged as a seminal contribution, offering a synthesis of computational parsimony and competitive performance in mobile vision applications. This paper conducts a meticulous examination of MobileNets, elucidating their architectural principles, methodological underpinnings, and empirical validations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffefb92",
   "metadata": {},
   "source": [
    "<b>Key Points:</b></br>\n",
    " - <i>Introduction to MobileNets:</i> MobileNets represent a significant advancement in convolutional neural network (CNN) architectures, specifically tailored to address the demands of mobile vision applications in light of the widespread use of mobile computing devices.\n",
    "\n",
    " - <i>Depthwise Separable Convolutions:</i> Different approach and innovation of depthwise separable convolutions, explaining its theoretical basis and how it enhances model efficiency by decomposing convolutions into separate depthwise and pointwise operations.\n",
    "\n",
    " - <i>Important components:</i> MobileNets' architecture is dissected, focusing on key components such as depthwise separable convolutions and linear bottlenecks. These architectural nuances contribute to MobileNets' distinctive computational efficiency.\n",
    "\n",
    " - <i>Progress:</i> We track the evolutionary development of MobileNets from their inception with MobileNetV1 to subsequent iterations like MobileNetV2 and MobileNetV3. This exploration highlights the iterative refinements that have led to improved performance and versatility.\n",
    "\n",
    " - <i>Evaluation:</i> Rigorous empirical evaluations conducted on benchmark datasets validate the effectiveness of MobileNets across various mobile vision tasks. These findings underscore MobileNets' competitive performance compared to traditional CNN architectures.\n",
    "\n",
    " - <i>Deployment:</i> MobileNets are shown to be practically deployable on mobile platforms due to their compact size, efficient computation, and energy-saving design. This practicality makes them well-suited for a wide range of mobile vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a02132",
   "metadata": {},
   "source": [
    "<b>Contribution:</b></br>\n",
    "In summary, MobileNets represent a blend of innovative science and practical usefulness, symbolizing a significant change towards efficient CNN architectures designed specifically for mobile vision applications. By combining depthwise separable convolutions with thoughtful architectural design, MobileNets achieve a balance between computational efficiency and performance accuracy. This places them at the forefront of mobile deep learning, playing a crucial role in the evolving landscape of mobile technology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edc912",
   "metadata": {},
   "source": [
    "<b>Other</b></br>\n",
    "Depthwise convolution with one filter per input channel (input depth) can be written as:\n",
    " \n",
    "$$ \\hat{G}_{k,l,m} = \\sum_{i,j} \\hat{K}_{i,j,m} \\cdot F_{k+i-1,l+j-1,m} $$\n",
    "\n",
    "where $\\hat{K}$ is the kernel with size $D_K \\cdot D_K \\cdot M$ where where the mth filter in  $\\hat{K}$ is applied to the mth channel in F to produce the mth channel of the filtered output feature map  $\\hat{G}$\n",
    "\n",
    "Depthwise convolution has a computational cost of:\n",
    "\n",
    "$$ D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F $$\n",
    "\n",
    "Depthwise separable convolutions cost:\n",
    "\n",
    "$$ D_K \\cdot D_K \\cdot M \\cdot D_F \\cdot D_F + M \\cdot N \\cdot D_F \\cdot D_F $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5ef60",
   "metadata": {},
   "source": [
    "Visual representation of standard convolutional filters  (a) , depthwise convolution in (b) and pointwise convolu-\n",
    "tion in (c) to build a depthwise separable filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64e894",
   "metadata": {},
   "source": [
    "<img src=\"images/filters.jpg\" alt=\"Filters\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
